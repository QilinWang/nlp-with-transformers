{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're on Colab or Kaggle\n",
    "# !git clone https://github.com/nlp-with-transformers/notebooks.git\n",
    "# %cd notebooks\n",
    "# from install import *\n",
    "# install_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers v4.11.3\n",
      "Using datasets v1.13.0\n",
      "Using accelerate v0.5.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from utils import *\n",
    "setup_chapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            0      1   2  3         4          5   6       7   8           9\nTokens   Jeff   Dean  is  a  computer  scientist  at  Google  in  California\nTags    B-PER  I-PER   O  O         O          O   O   B-ORG   O       B-LOC",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>Jeff</td>\n      <td>Dean</td>\n      <td>is</td>\n      <td>a</td>\n      <td>computer</td>\n      <td>scientist</td>\n      <td>at</td>\n      <td>Google</td>\n      <td>in</td>\n      <td>California</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>O</td>\n      <td>B-LOC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "toks = \"Jeff Dean is a computer scientist at Google in California\".split()\n",
    "lbls = [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"B-LOC\"]\n",
    "df = pd.DataFrame(data=[toks, lbls], index=['Tokens', 'Tags'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['XNLI', 'tydiqa', 'SQuAD', 'PAN-X.af', 'PAN-X.ar']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtreme_subsets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xtreme (C:/Users/qilin/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35a85239e9364b37828aff9345c45346"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'langs'],\n        num_rows: 20000\n    })\n    validation: Dataset({\n        features: ['tokens', 'ner_tags', 'langs'],\n        num_rows: 10000\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags', 'langs'],\n        num_rows: 10000\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dataset(\"xtreme\", name=\"PAN-X.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xtreme (C:/Users/qilin/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95e2c4caeb0a4c28a4f4d1f2e1c80329"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-e5ddf09f1ae095ec.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-25e7e2dd003d0fa6.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-73a95bc0accfea8b.arrow\n",
      "Found cached dataset xtreme (C:/Users/qilin/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "722510a83ceb4fe59a7c907f01fdf09a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-6ff29513007ec78b.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-c5c9a4fc19dfd7d6.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-9711ab25936b81b7.arrow\n",
      "Found cached dataset xtreme (C:/Users/qilin/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "549360b262c84304b8840e57748bb729"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-daa9a1770078307c.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-5e244c05031bab3c.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-497ee15c12bff58d.arrow\n",
      "Found cached dataset xtreme (C:/Users/qilin/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3b98af893964a9cae2428b14c215d9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-757845faa9fa6949.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-305cefc7ffa49fd9.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-e5ec5e6ba7c1237d.arrow\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# Return a DatasetDict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "panx_ch\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "            .shuffle(seed=0)\n",
    "            .select(range(int(frac * ds[split].num_rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['tokens', 'ner_tags', 'langs'],\n    num_rows: 1180\n})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch['en']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "             index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():  # : panx_ch[\"de\"][\"train\"].features is a dict\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n",
      "I-ORG\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)\n",
    "print(tags.int2str(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-f3309bc5e9d28268.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-36ed4bdaca6e2a48.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-a08bda4878cb6bac.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
      "        num_rows: 12580\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
      "        num_rows: 6290\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
      "        num_rows: 6290\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)  # : so this mapping creates additional features named 'ner_tags_str'\n",
    "print(panx_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Closer Look at Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BERT</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Spa</td>\n",
       "      <td>##rrow</td>\n",
       "      <td>loves</td>\n",
       "      <td>New</td>\n",
       "      <td>York</td>\n",
       "      <td>!</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLM-R</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2       3      4    5     6      7      8     9\n",
       "BERT   [CLS]   Jack    Spa  ##rrow  loves  New  York      !  [SEP]  None\n",
       "XLM-R    <s>  ▁Jack  ▁Spar     row  ▁love    s  ▁New  ▁York      !  </s>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "df = pd.DataFrame([bert_tokens, xlmr_tokens], index=[\"BERT\", \"XLM-R\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Tokenizer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Tokenizer pipeline\" caption=\"The steps in the tokenization pipeline\" src=\"images/chapter04_tokenizer-pipeline.png\" id=\"toknizer-pipeline\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SentencePiece Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>▁Jack▁Sparrow▁loves▁New▁York!</s>\n",
      "<s> Jack Sparrow loves New York!</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(xlmr_tokens))\n",
    "print(\"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[train_ner_tagger]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers for Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Architecture of a transformer encoder for classification.\" caption=\"Fine-tuning an encoder-based transformer for sequence classification\" src=\"images/chapter04_clf-architecture.png\" id=\"clf-arch\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Architecture of a transformer encoder for named entity recognition. The wide linear layer shows that the same linear layer is applied to all hidden states.\" caption=\"Fine-tuning an encoder-based transformer for named entity recognition\" src=\"images/chapter04_ner-architecture.png\" id=\"ner-arch\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Anatomy of the Transformers Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bodies and Heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"bert-body-head\" caption=\"The `BertModel` class only contains the body of the model, while the `BertFor&lt;Task&gt;` classes combine the body with a dedicated head for a given task\" src=\"images/chapter04_bert-body-head.png\" id=\"bert-body-head\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Model for Token Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)  # : return all, not just CLS\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
    "                labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))  # : loss(input, label)\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits,  # : TokenClassifierOutput class\n",
    "                                     hidden_states=outputs.hidden_states, \n",
    "                                     attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xlmr_model = (XLMRobertaForTokenClassification\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             0      1      2      3      4  5     6      7   8     9\nTokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\nInput IDs    0  21763  37456  15555   5161  7  2356   5753  38     2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Input IDs</th>\n      <td>0</td>\n      <td>21763</td>\n      <td>37456</td>\n      <td>15555</td>\n      <td>5161</td>\n      <td>7</td>\n      <td>2356</td>\n      <td>5753</td>\n      <td>38</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=None, logits=tensor([[[ 2.9491e-01, -1.4722e-01,  2.3203e-01, -5.8347e-01, -3.7713e-02,\n",
       "          -5.8250e-02, -9.1335e-01],\n",
       "         [ 9.9618e-02, -3.9073e-01,  2.5161e-01, -2.1589e-04, -1.6590e-02,\n",
       "           1.3126e-01, -7.0890e-01],\n",
       "         [ 7.8177e-02, -3.9373e-01,  3.0029e-01, -8.0473e-02,  5.6447e-02,\n",
       "           1.2184e-01, -6.4477e-01],\n",
       "         [ 1.8236e-01, -4.4992e-01,  2.5176e-01,  2.4101e-02, -1.8578e-02,\n",
       "           5.3543e-02, -7.4407e-01],\n",
       "         [ 1.8414e-01, -3.6823e-01,  2.4701e-01, -1.9518e-02,  6.5516e-03,\n",
       "           3.6565e-02, -7.3769e-01],\n",
       "         [ 2.5685e-01, -3.3242e-01,  2.0399e-01, -2.0063e-02, -4.3463e-02,\n",
       "          -1.5657e-02, -7.3047e-01],\n",
       "         [ 1.5265e-01, -4.2270e-01,  1.8858e-01,  5.8963e-02,  4.8361e-02,\n",
       "           1.5310e-01, -7.0945e-01],\n",
       "         [ 1.2026e-01, -4.1626e-01,  2.4344e-01,  1.5473e-02,  1.6552e-02,\n",
       "           1.4508e-01, -7.0965e-01],\n",
       "         [ 1.9520e-01, -3.4426e-01,  2.1003e-01,  1.9844e-02, -2.4233e-02,\n",
       "           4.8643e-02, -7.3080e-01],\n",
       "         [ 2.6967e-01, -1.8613e-01,  2.8182e-01, -5.8332e-01, -2.4020e-02,\n",
       "          -9.5896e-02, -9.6906e-01]]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# : note\n",
    "xlmr_model(input_ids.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.names  # :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4  5      6      7      8      9\n",
       "Tokens  <s>  ▁Jack  ▁Spar    row  ▁love  s   ▁New  ▁York      !   </s>\n",
       "Tags      O  I-PER  I-PER  I-PER  I-PER  O  I-PER  I-PER  I-PER  I-PER"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])  # : very poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# : wrap everything into a helper function\n",
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # Get tokens with special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    # Encode the sequence into IDs\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    # Get predictions as distribution over 7 possible classes\n",
    "    outputs = model(input_ids)[0]\n",
    "    # Take argmax to get most likely class per token\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    # Convert to DataFrame\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Texts for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2.000',\n",
       "  'Einwohnern',\n",
       "  'an',\n",
       "  'der',\n",
       "  'Danziger',\n",
       "  'Bucht',\n",
       "  'in',\n",
       "  'der',\n",
       "  'polnischen',\n",
       "  'Woiwodschaft',\n",
       "  'Pommern',\n",
       "  '.'],\n",
       " [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, labels  # :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15  \\\n",
       "Tokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "pd.DataFrame([tokens], index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "Word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])  # : labels was int index\n",
    "    previous_word_idx = word_idx\n",
    "    \n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! to the whole dataset\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, \n",
    "                                      is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True, \n",
    "                      remove_columns=['langs', 'ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-d76c2dcc0ec782ff.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-09bf7bdc09191ef8.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-4902ff88ff9769c6.arrow\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de_encoded['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 7\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\", \n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, \n",
    "    logging_steps=logging_steps, push_to_hub=True,\n",
    "    report_to=\"none\")  # : extra for disabling neptune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (manager-core).\n",
      "Your token has been saved to C:\\Users\\qilin\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions, \n",
    "                                       eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\qilin\\CloudStation\\_MILA\\6289\\nlp-with-transformers\\xlm-roberta-base-finetuned-panx-de is already a clone of https://huggingface.co/qilin1/xlm-roberta-base-finetuned-panx-de. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,  # no longer model, but model_init\n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=panx_de_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_encoded[\"validation\"], \n",
    "                  tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qilin\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='7548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/7548 : < :, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc32e6d80f54cd3ad47249976b41e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc46fe8de16b4490b251566f37619486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file tokenizer.json:   0%|          | 32.0k/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d788cdc323475da82f3ac9a97b3dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin: 100%|##########| 3.42k/3.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d56dd0f6a749bc8049cfa3cf78356b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file sentencepiece.bpe.model:   1%|          | 32.0k/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files of refs/heads/main for validity...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/qilin1/xlm-roberta-base-finetuned-panx-de\n",
      "   a14f875..67645fc  main -> main\n",
      "\n",
      "To https://huggingface.co/qilin1/xlm-roberta-base-finetuned-panx-de\n",
      "   67645fc..904a827  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/qilin1/xlm-roberta-base-finetuned-panx-de/commit/67645fc1333ad17acad3576da66c501f31c86e23'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.2652</td>\n",
       "      <td>0.160244</td>\n",
       "      <td>0.822974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.1314</td>\n",
       "      <td>0.137195</td>\n",
       "      <td>0.852747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.138774</td>\n",
       "      <td>0.864591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "df = pd.DataFrame(trainer.state.log_history)[['epoch','loss' ,'eval_loss', 'eval_f1']]\n",
    "df = df.rename(columns={\"epoch\":\"Epoch\",\"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", \"eval_f1\":\"F1\"})\n",
    "df['Epoch'] = df[\"Epoch\"].apply(lambda x: round(x))\n",
    "df['Training Loss'] = df[\"Training Loss\"].ffill()\n",
    "df[['Validation Loss', 'F1']] = df[['Validation Loss', 'F1']].bfill().ffill()\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁ist</td>\n",
       "      <td>▁ein</td>\n",
       "      <td>▁Informati</td>\n",
       "      <td>ker</td>\n",
       "      <td>▁bei</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Kaliforni</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4     5           6    7     8        9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google   \n",
       "Tags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n",
       "\n",
       "         10          11     12    13  \n",
       "Tokens  ▁in  ▁Kaliforni     en  </s>  \n",
       "Tags      O       B-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fruit': ['apple', 'banana', 'orange'], 'color': ['red', 'yellow', 'orange']}\n",
      "dict_values([['apple', 'banana', 'orange'], ['red', 'yellow', 'orange']])\n",
      "['apple', 'banana', 'orange'] ['red', 'yellow', 'orange']\n",
      "-----\n",
      "[('apple', 'red'), ('banana', 'yellow'), ('orange', 'orange')]\n",
      "[[('fruit', 'apple'), ('color', 'red')], [('fruit', 'banana'), ('color', 'yellow')], [('fruit', 'orange'), ('color', 'orange')]]\n",
      "-----\n",
      "[{'fruit': 'apple', 'color': 'red'}, {'fruit': 'banana', 'color': 'yellow'}, {'fruit': 'orange', 'color': 'orange'}]\n"
     ]
    }
   ],
   "source": [
    "# gpt example\n",
    "# Dictionary of lists\n",
    "dict_of_lists = {'fruit': ['apple', 'banana', 'orange'], 'color': ['red', 'yellow', 'orange']}\n",
    "print(dict_of_lists)\n",
    "print(dict_of_lists.values())\n",
    "print(*dict_of_lists.values())\n",
    "print(f'-----')\n",
    "# Convert dictionary of lists to list of dictionaries\n",
    "print([t for t in zip(*dict_of_lists.values())])\n",
    "print([list(zip(dict_of_lists, t)) for t in zip(*dict_of_lists.values())])\n",
    "\n",
    "list_of_dicts = [dict(zip(dict_of_lists, t)) for t in zip(*dict_of_lists.values())]\n",
    "print(f'-----')\n",
    "# Output the result\n",
    "print(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model  \n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # Logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7), \n",
    "                         labels.view(-1), reduction=\"none\")  # : two ways of using cross_entropy: with classes or with probabilities\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function forward_pass_with_label at 0x0000022328F9C3A0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b3f4c90e6d45acb8428faf0b062fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 0.0017051456, 0.0, 0.0036322589, 0.00301...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            input_ids         attention_mask  \\\n",
       "0  [0, 10699, 11, 15, 16104, 1388, 2]  [1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                        labels  \\\n",
       "0  [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.0017051456, 0.0, 0.0036322589, 0.00301...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]   \n",
       "\n",
       "                                 input_tokens  \n",
       "0  [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "df = valid_set.to_pandas()\n",
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df['loss'] = df.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df['predicted_label'] = df.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10699</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16104</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56530</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.01</td>\n",
       "      <td>O</td>\n",
       "      <td>▁WE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83982</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.15</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Luz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.23</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label  input_tokens\n",
       "0     10699              1  B-ORG  0.00           B-ORG          ▁Ham\n",
       "0        15              1  I-ORG  0.00           I-ORG            ▁(\n",
       "0     16104              1  I-ORG  0.00           I-ORG  ▁Unternehmen\n",
       "0      1388              1  I-ORG  0.00           I-ORG            ▁)\n",
       "1     56530              1      O  0.01               O           ▁WE\n",
       "1     83982              1  B-ORG  0.15           B-ORG          ▁Luz\n",
       "1        10              1  I-ORG  0.23           I-ORG            ▁a"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁A</td>\n",
       "      <td>▁/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>1388</td>\n",
       "      <td>989</td>\n",
       "      <td>808</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>1171</td>\n",
       "      <td>2898</td>\n",
       "      <td>125</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>259.43</td>\n",
       "      <td>211.95</td>\n",
       "      <td>150.38</td>\n",
       "      <td>147.33</td>\n",
       "      <td>133.34</td>\n",
       "      <td>124.58</td>\n",
       "      <td>122.23</td>\n",
       "      <td>85.11</td>\n",
       "      <td>84.53</td>\n",
       "      <td>80.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2       3       4       5       6      7  \\\n",
       "input_tokens       ▁    ▁der     ▁in    ▁von      ▁(      ▁)    ▁und    ▁''   \n",
       "count           6066    1388     989     808     246     246    1171   2898   \n",
       "mean            0.04    0.15    0.15    0.18    0.54    0.51     0.1   0.03   \n",
       "sum           259.43  211.95  150.38  147.33  133.34  124.58  122.23  85.11   \n",
       "\n",
       "                  8      9  \n",
       "input_tokens     ▁A     ▁/  \n",
       "count           125    163  \n",
       "mean           0.68    0.5  \n",
       "sum           84.53  80.82  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1462</td>\n",
       "      <td>2683</td>\n",
       "      <td>3820</td>\n",
       "      <td>3172</td>\n",
       "      <td>2893</td>\n",
       "      <td>4139</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1338.38</td>\n",
       "      <td>1996.54</td>\n",
       "      <td>2322.56</td>\n",
       "      <td>1499.1</td>\n",
       "      <td>961.58</td>\n",
       "      <td>1037.35</td>\n",
       "      <td>1659.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2       3       4        5        6\n",
       "labels    I-LOC    B-ORG    I-ORG   B-LOC   B-PER    I-PER        O\n",
       "count      1462     2683     3820    3172    2893     4139    43648\n",
       "mean       0.92     0.74     0.61    0.47    0.33     0.25     0.04\n",
       "sum     1338.38  1996.54  2322.56  1499.1  961.58  1037.35  1659.93"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]] \n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .sort_values(by=\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"],\n",
    "                      tags.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n",
      "\n",
      "\n",
      "Index: 0\n",
      "Name: Alice\n",
      "Age: 25\n",
      "Index: 1\n",
      "Name: Bob\n",
      "Age: 30\n",
      "Index: 2\n",
      "Name: Charlie\n",
      "Age: 35\n"
     ]
    }
   ],
   "source": [
    "# gpt\n",
    "import pandas as pd\n",
    "# df.iterrows()\n",
    "# It returns an iterator that yields both the index and row data as a tuple.\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df1 = pd.DataFrame({'name': ['Alice', 'Bob', 'Charlie'], 'age': [25, 30, 35]})\n",
    "print(df1)\n",
    "print(\"\\n\")\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in df1.iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"Name: {row['name']}\")\n",
    "    print(f\"Age: {row['age']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator started!\n",
      "Received value: 1\n",
      "Value 1 yielded!\n",
      "Received value: 2\n",
      "Value 2 yielded!\n",
      "Received value: 3\n",
      "Value 3 yielded!\n",
      "Generator finished!\n"
     ]
    }
   ],
   "source": [
    "# gpt\n",
    "# In Python, yield is used in a function to define a generator. A generator is a special type of iterator that can be paused and resumed at any time, allowing the function to return a series of values one at a time instead of all at once.\n",
    "\n",
    "def my_generator():\n",
    "    print(\"Generator started!\")\n",
    "    yield 1\n",
    "    print(\"Value 1 yielded!\")\n",
    "    yield 2\n",
    "    print(\"Value 2 yielded!\")\n",
    "    yield 3\n",
    "    print(\"Value 3 yielded!\")\n",
    "    print(\"Generator finished!\")\n",
    "\n",
    "gen = my_generator() # create a generator object\n",
    "\n",
    "for value in gen:\n",
    "    print(\"Received value:\", value)\n",
    "\n",
    "# When you start iterating over the generator object gen, the function is executed up to the first yield statement.\n",
    "# The value of 1 is returned from the generator, and the function is paused at the yield statement.\n",
    "# When you iterate over the generator object again, the function resumes execution immediately after the last yield statement.\n",
    "# the second yield statement is encountered, and the value of 2 is returned from the generator. The function is paused again.\n",
    "# The process repeats for the third yield statement, returning 3.\n",
    "# Since there are no more yield statements in the function, the generator function is complete and the generator object is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁Τ</td>\n",
       "      <td>Κ</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁T</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ri</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>k</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ala</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.98</td>\n",
       "      <td>11.49</td>\n",
       "      <td>8.48</td>\n",
       "      <td>9.73</td>\n",
       "      <td>8.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.39</td>\n",
       "      <td>9.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.17</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2     3     4     5      6      7      8      9   \\\n",
       "tokens    ▁'   ▁''     ▁Τ     Κ   ▁''    ▁'     ▁'    ▁''     ▁T    ▁''   \n",
       "labels     O     O      O   IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \n",
       "preds      O     O  B-ORG     O     O     O      O      O      O      O   \n",
       "losses  0.00  0.00   2.18  0.00  0.00  0.00  11.98  11.49   8.48   9.73   \n",
       "\n",
       "           10    11     12     13    14     15     16    17    18  \n",
       "tokens     ▁'    ri    ▁''     ▁'     k    ▁''     ▁'   ala  </s>  \n",
       "labels  I-LOC   IGN  I-LOC  I-LOC   IGN  I-LOC  I-LOC   IGN   IGN  \n",
       "preds       O     O      O      O     O      O      O     O     O  \n",
       "losses   8.86  0.00  10.39   9.41  0.00  10.17   9.26  0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁''</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>▁Juli</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁:</td>\n",
       "      <td>▁Protest</td>\n",
       "      <td>camp</td>\n",
       "      <td>▁auf</td>\n",
       "      <td>▁dem</td>\n",
       "      <td>▁Gelände</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Republika</td>\n",
       "      <td>n</td>\n",
       "      <td>ischen</td>\n",
       "      <td>▁Gar</td>\n",
       "      <td>de</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>10.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.04</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.57</td>\n",
       "      <td>9.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.98</td>\n",
       "      <td>8.59</td>\n",
       "      <td>8.02</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2      3      4      5         6     7      8      9   \\\n",
       "tokens    ▁''     8     .  ▁Juli    ▁''     ▁:  ▁Protest  camp   ▁auf   ▁dem   \n",
       "labels  B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG  I-ORG   \n",
       "preds       O     O     O      O      O      O         O     O      O      O   \n",
       "losses  10.61  0.00  0.00   8.04  10.80  10.57      9.06  0.00   8.48   8.98   \n",
       "\n",
       "              10     11          12     13      14     15     16    17  \n",
       "tokens  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de  </s>  \n",
       "labels     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN   IGN  \n",
       "preds          O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG     O  \n",
       "losses      8.59   8.02        8.66   0.00    0.00   0.00   0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁United</td>\n",
       "      <td>▁Nations</td>\n",
       "      <td>▁Multi</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>▁Integra</td>\n",
       "      <td>ted</td>\n",
       "      <td>▁Stabil</td>\n",
       "      <td>ization</td>\n",
       "      <td>▁Mission</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁Central</td>\n",
       "      <td>▁African</td>\n",
       "      <td>▁Republic</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>8.44</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.12</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.34</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1       2            3         4      5        6   \\\n",
       "tokens  ▁United  ▁Nations  ▁Multi  dimensional  ▁Integra    ted  ▁Stabil   \n",
       "labels    B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \n",
       "preds     B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \n",
       "losses     8.44      7.41    7.60         0.00      7.41   0.00     7.38   \n",
       "\n",
       "             7         8      9      10        11        12         13     14  \n",
       "tokens  ization  ▁Mission    ▁in   ▁the  ▁Central  ▁African  ▁Republic   </s>  \n",
       "labels      IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER    IGN  \n",
       "preds     I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  I-ORG  \n",
       "losses     0.00      7.12   6.88   7.21      7.58      7.34       7.08   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \n",
    "                               \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp\n",
    "\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Ham</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2             3      4      5\n",
       "tokens   ▁Ham      a     ▁(  ▁Unternehmen     ▁)   </s>\n",
       "labels  B-ORG    IGN  I-ORG         I-ORG  I-ORG    IGN\n",
       "preds   B-ORG  I-ORG  I-ORG         I-ORG  I-ORG  I-ORG\n",
       "losses   0.00   0.00   0.00          0.00   0.00   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Kesk</td>\n",
       "      <td>kül</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Mart</td>\n",
       "      <td>na</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7\n",
       "tokens  ▁Kesk    kül      a     ▁(  ▁Mart     na     ▁)   </s>\n",
       "labels  B-LOC    IGN    IGN  I-LOC  I-LOC    IGN  I-LOC    IGN\n",
       "preds   B-LOC  I-LOC  B-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\n",
       "losses   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "df_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Lingual Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='2097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/2097 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [30]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m f1_scores \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28mdict\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m f1_scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mde\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mde\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mget_f1_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpanx_de_encoded\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF1-score of [de] model on [de] dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf1_scores[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mde\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mde\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[1;32mIn [29]\u001B[0m, in \u001B[0;36mget_f1_score\u001B[1;34m(trainer, dataset)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_f1_score\u001B[39m(trainer, dataset):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mmetrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_f1\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\trainer.py:2903\u001B[0m, in \u001B[0;36mTrainer.predict\u001B[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   2900\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   2902\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[1;32m-> 2903\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2904\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPrediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\n\u001B[0;32m   2905\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2906\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[0;32m   2907\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\trainer.py:3009\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3006\u001B[0m         batch_size \u001B[38;5;241m=\u001B[39m observed_batch_size\n\u001B[0;32m   3008\u001B[0m \u001B[38;5;66;03m# Prediction step\u001B[39;00m\n\u001B[1;32m-> 3009\u001B[0m loss, logits, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprediction_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3010\u001B[0m inputs_decode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_input(inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39minclude_inputs_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   3012\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_torch_tpu_available():\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\trainer.py:3264\u001B[0m, in \u001B[0;36mTrainer.prediction_step\u001B[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001B[0m\n\u001B[0;32m   3262\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_labels \u001B[38;5;129;01mor\u001B[39;00m loss_without_labels:\n\u001B[0;32m   3263\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[1;32m-> 3264\u001B[0m         loss, outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   3265\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[0;32m   3267\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\trainer.py:2571\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[1;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[0;32m   2569\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2570\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2571\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[0;32m   2572\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[0;32m   2573\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[0;32m   2574\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36mXLMRobertaForTokenClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, labels, **kwargs)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, attention_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, token_type_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \n\u001B[0;32m     22\u001B[0m             labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;66;03m# Use model body to get encoder representations\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroberta(input_ids, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m     25\u001B[0m                            token_type_ids\u001B[38;5;241m=\u001B[39mtoken_type_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;66;03m# Apply classifier to encoder representation\u001B[39;00m\n\u001B[0;32m     27\u001B[0m     sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(outputs[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:851\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    842\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m    844\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m    845\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m    846\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    849\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m    850\u001B[0m )\n\u001B[1;32m--> 851\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    855\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    863\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    864\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:526\u001B[0m, in \u001B[0;36mRobertaEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    517\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    518\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    519\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[0;32m    525\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 526\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    530\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    532\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    533\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    534\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    536\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:411\u001B[0m, in \u001B[0;36mRobertaLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    401\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    408\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    410\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 411\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    418\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    420\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:338\u001B[0m, in \u001B[0;36mRobertaAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    328\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    330\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    336\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    337\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m--> 338\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    340\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    345\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    347\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    348\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:195\u001B[0m, in \u001B[0;36mRobertaSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    187\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    193\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    194\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m--> 195\u001B[0m     mixed_query_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001B[39;00m\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001B[39;00m\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001B[39;00m\n\u001B[0;32m    200\u001B[0m     is_cross_attention \u001B[38;5;241m=\u001B[39m encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁est</td>\n",
       "      <td>▁informatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>▁chez</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁en</td>\n",
       "      <td>▁Cali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4            5    6      7        8    9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁est  ▁informatic  ien  ▁chez  ▁Google  ▁en   \n",
       "Tags      O  B-PER  I-PER  I-PER     O            O    O      O    B-ORG    O   \n",
       "\n",
       "           10     11     12    13  \n",
       "Tokens  ▁Cali    for    nie  </s>  \n",
       "Tags    B-LOC  B-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cda547ce7c842738d2dd75d7ca7a517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6642dabb2bf048e3a43c748640ebe800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502fb8a15a244c5ba5831913a25951dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1/458 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [fr] dataset: 0.707\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [fr] dataset: 0.707\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8600f8c8b94654b79bca154dfc4163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424ac72b07384b02996e22acb4666436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ff2453d6384d34aeae7a8d2dee8eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1/168 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [it] dataset: 0.667\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [it] dataset: 0.667\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_lang_performance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#hide_output\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m f1_scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mde\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_lang_performance\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m\"\u001B[39m, trainer)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF1-score of [de] model on [en] dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf1_scores[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mde\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'evaluate_lang_performance' is not defined"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [en] dataset: 0.576\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When Does Zero-Shot Transfer Make Sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_subset(dataset, num_samples):\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "    \n",
    "    trainer = Trainer(model_init=model_init, args=training_args,\n",
    "        data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "        train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n",
    "    trainer.train()\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(commit_message=\"Training completed!\")\n",
    "    \n",
    "    f1_score = get_f1_score(trainer, test_ds)\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-e1919ac3c2a04d9a.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62a27a8a44ea42b3b7993da9898e1fdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-b04adacda5246119.arrow\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qilin\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/252 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/764 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   num_samples  f1_score\n0          250   0.71222",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_samples</th>\n      <th>f1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>250</td>\n      <td>0.71222</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "training_args.push_to_hub = False\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-ebb3d0cada8e5d39.arrow\n",
      "C:\\Users\\qilin\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/501 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/764 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qilin\\AppData\\Local\\Temp\\ipykernel_40356\\474267531.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append(\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-ebb3d0cada8e5d39.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1002 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/764 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-ebb3d0cada8e5d39.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2001 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/764 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-ebb3d0cada8e5d39.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='4002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/4002 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/764 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "for num_samples in [500, 1000, 2000, 4000]:\n",
    "    metrics_df = metrics_df.append(\n",
    "        train_on_subset(panx_fr_encoded, num_samples), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "# ax.axhline(f1_scores[\"de\"][\"fr\"], ls=\"--\", color=\"r\")\n",
    "metrics_df.set_index(\"num_samples\").plot(ax=ax)\n",
    "plt.legend([\"Zero-shot from de\", \"Fine-tuned on fr\"], loc=\"lower right\")\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Fine-Tuning on Multiple Languages at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "def concatenate_splits(corpora):\n",
    "    multi_corpus = DatasetDict()\n",
    "    for split in corpora[0].keys():\n",
    "        multi_corpus[split] = concatenate_datasets(\n",
    "            [corpus[split] for corpus in corpora]).shuffle(seed=42)\n",
    "    return multi_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panx_de_fr_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/qilin1/xlm-roberta-base-finetuned-panx-de-fr into local empty directory.\n",
      "C:\\Users\\qilin\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='17160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    2/17160 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Upload file pytorch_model.bin:   0%|          | 32.0k/1.03G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef7aaafbcd4a489ead0f6d5e22c6d84c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Upload file sentencepiece.bpe.model:   1%|          | 32.0k/4.83M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e26ae354e2f402da012b6b420271dce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Upload file tokenizer.json:   0%|          | 32.0k/16.3M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffc2039236464847be12078c704ac9c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Upload file training_args.bin: 100%|##########| 3.48k/3.48k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81c3ccc2d35140afb4d0135246723afb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [43]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(model_init\u001B[38;5;241m=\u001B[39mmodel_init, args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m      7\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mdata_collator, compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[0;32m      8\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mxlmr_tokenizer, train_dataset\u001B[38;5;241m=\u001B[39mpanx_de_fr_encoded[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m      9\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mpanx_de_fr_encoded[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     11\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m---> 12\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTraining completed!\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\trainer.py:3492\u001B[0m, in \u001B[0;36mTrainer.push_to_hub\u001B[1;34m(self, commit_message, blocking, **kwargs)\u001B[0m\n\u001B[0;32m   3489\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpush_in_progress\u001B[38;5;241m.\u001B[39m_process\u001B[38;5;241m.\u001B[39mkill()\n\u001B[0;32m   3490\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpush_in_progress \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 3492\u001B[0m git_head_commit_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3493\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_message\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblocking\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauto_lfs_prune\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m   3494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3495\u001B[0m \u001B[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001B[39;00m\n\u001B[0;32m   3496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mshould_save:\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\huggingface_hub\\repository.py:1368\u001B[0m, in \u001B[0;36mRepository.push_to_hub\u001B[1;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001B[0m\n\u001B[0;32m   1366\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgit_add(auto_lfs_track\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1367\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgit_commit(commit_message)\n\u001B[1;32m-> 1368\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgit_push\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1369\u001B[0m \u001B[43m    \u001B[49m\u001B[43mupstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43morigin \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_branch\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1370\u001B[0m \u001B[43m    \u001B[49m\u001B[43mblocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1371\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauto_lfs_prune\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauto_lfs_prune\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1372\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\huggingface_hub\\repository.py:1135\u001B[0m, in \u001B[0;36mRepository.git_push\u001B[1;34m(self, upstream, blocking, auto_lfs_prune)\u001B[0m\n\u001B[0;32m   1126\u001B[0m process \u001B[38;5;241m=\u001B[39m subprocess\u001B[38;5;241m.\u001B[39mPopen(\n\u001B[0;32m   1127\u001B[0m     command\u001B[38;5;241m.\u001B[39msplit(),\n\u001B[0;32m   1128\u001B[0m     stderr\u001B[38;5;241m=\u001B[39msubprocess\u001B[38;5;241m.\u001B[39mPIPE,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1131\u001B[0m     cwd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_dir,\n\u001B[0;32m   1132\u001B[0m )\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m blocking:\n\u001B[1;32m-> 1135\u001B[0m     stdout, stderr \u001B[38;5;241m=\u001B[39m \u001B[43mprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcommunicate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1136\u001B[0m     return_code \u001B[38;5;241m=\u001B[39m process\u001B[38;5;241m.\u001B[39mpoll()\n\u001B[0;32m   1137\u001B[0m     process\u001B[38;5;241m.\u001B[39mkill()\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\subprocess.py:1149\u001B[0m, in \u001B[0;36mPopen.communicate\u001B[1;34m(self, input, timeout)\u001B[0m\n\u001B[0;32m   1146\u001B[0m     endtime \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1148\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1149\u001B[0m     stdout, stderr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_communicate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendtime\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1151\u001B[0m     \u001B[38;5;66;03m# https://bugs.python.org/issue25942\u001B[39;00m\n\u001B[0;32m   1152\u001B[0m     \u001B[38;5;66;03m# See the detailed comment in .wait().\u001B[39;00m\n\u001B[0;32m   1153\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\subprocess.py:1523\u001B[0m, in \u001B[0;36mPopen._communicate\u001B[1;34m(self, input, endtime, orig_timeout)\u001B[0m\n\u001B[0;32m   1519\u001B[0m \u001B[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001B[39;00m\n\u001B[0;32m   1520\u001B[0m \u001B[38;5;66;03m# threads remain reading and the fds left open in case the user\u001B[39;00m\n\u001B[0;32m   1521\u001B[0m \u001B[38;5;66;03m# calls communicate again.\u001B[39;00m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1523\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstdout_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_remaining_time\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendtime\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1524\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdout_thread\u001B[38;5;241m.\u001B[39mis_alive():\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m TimeoutExpired(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, orig_timeout)\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\threading.py:1089\u001B[0m, in \u001B[0;36mThread.join\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1088\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1089\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1090\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1091\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\threading.py:1109\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m   1106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1110\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m   1111\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "training_args.logging_steps = len(panx_de_fr_encoded[\"train\"]) // batch_size\n",
    "training_args.push_to_hub = True\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=panx_de_fr_encoded[\"train\"],\n",
    "    eval_dataset=panx_de_fr_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/12580 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d71db9bfbe44936945526f9391947ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "426b62b0709349fdba20f20a5b21fcc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c01a008e3216486fbdfa305cfc9957bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='2097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/2097 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-0ce791e258df6488.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-88460cc0709a509a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-b04adacda5246119.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [de] dataset: 0.861\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/764 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-f3fee4c36f9ac67b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-0c5a559295aaefee.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-b90402de861e6a85.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [fr] dataset: 0.858\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/280 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-a6964af9da4e0308.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-aaa790ce8d0eb1cd.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-63d4abbcd16b6023.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [it] dataset: 0.758\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/197 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [en] dataset: 0.673\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-a5e8d4341bff0264.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-71422318581e93e5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.de\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-b0635f1fad4df39e.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='2097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/2097 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-0ce791e258df6488.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-88460cc0709a509a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-b04adacda5246119.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [de] dataset: 0.861\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/764 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-f3fee4c36f9ac67b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-0c5a559295aaefee.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.it\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-b90402de861e6a85.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [fr] dataset: 0.858\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/280 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-a6964af9da4e0308.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-aaa790ce8d0eb1cd.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.en\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-63d4abbcd16b6023.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [it] dataset: 0.758\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/197 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [en] dataset: 0.673\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hide_output\n",
    "corpora = [panx_de_encoded]\n",
    "corpora, langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Exclude German from iteration\n",
    "for lang in langs[1:]:\n",
    "    training_args.output_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n",
    "    # Fine-tune on monolingual corpus\n",
    "    ds_encoded = encode_panx_dataset(panx_ch[lang])\n",
    "    metrics = train_on_subset(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
    "    # Collect F1-scores in common dict\n",
    "    f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
    "    # Add monolingual corpus to list of corpora to concatenate\n",
    "    corpora.append(ds_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora_encoded = concatenate_splits(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hide_output\n",
    "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],\n",
    "    eval_dataset=corpora_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hide_output\n",
    "for idx, lang in enumerate(langs):\n",
    "    f1_scores[\"all\"][lang] = get_f1_score(trainer, corpora[idx][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_data = {\"de\": f1_scores[\"de\"],\n",
    "               \"each\": {lang: f1_scores[lang][lang] for lang in langs},\n",
    "               \"all\": f1_scores[\"all\"]}\n",
    "f1_scores_df = pd.DataFrame(scores_data).T.round(4)\n",
    "f1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\",\n",
    "                         inplace=True)\n",
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Interacting with Model Widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img alt=\"A Hub widget\" caption=\"Example of a widget on the Hugging Face Hub\" src=\"images/chapter04_ner-widget.png\" id=\"ner-widget\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-b282eaeed5f7962e.arrow\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB (GPU 0; 12.00 GiB total capacity; 10.35 GiB already allocated; 0 bytes free; 10.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [109]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# hide_output\u001B[39;00m\n\u001B[0;32m      2\u001B[0m training_args\u001B[38;5;241m.\u001B[39mpush_to_hub \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m metrics_df \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_on_subset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpanx_fr_encoded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m250\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m metrics_df\n",
      "Input \u001B[1;32mIn [106]\u001B[0m, in \u001B[0;36mtrain_on_subset\u001B[1;34m(dataset, num_samples)\u001B[0m\n\u001B[0;32m      5\u001B[0m training_args\u001B[38;5;241m.\u001B[39mlogging_steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_ds) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m batch_size\n\u001B[0;32m      7\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(model_init\u001B[38;5;241m=\u001B[39mmodel_init, args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m      8\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mdata_collator, compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[0;32m      9\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mtrain_ds, eval_dataset\u001B[38;5;241m=\u001B[39mvalid_ds, tokenizer\u001B[38;5;241m=\u001B[39mxlmr_tokenizer)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training_args\u001B[38;5;241m.\u001B[39mpush_to_hub:\n\u001B[0;32m     12\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mpush_to_hub(commit_message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining completed!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\trainer.py:1520\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_init \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1518\u001B[0m     \u001B[38;5;66;03m# Seed must be set before instantiating the model when using model_init.\u001B[39;00m\n\u001B[0;32m   1519\u001B[0m     enable_full_determinism(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mseed) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mfull_determinism \u001B[38;5;28;01melse\u001B[39;00m set_seed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mseed)\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_model_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1521\u001B[0m     model_reloaded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1522\u001B[0m     \u001B[38;5;66;03m# Reinitializes optimizer and scheduler\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\trainer.py:1260\u001B[0m, in \u001B[0;36mTrainer.call_model_init\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m   1258\u001B[0m model_init_argcount \u001B[38;5;241m=\u001B[39m number_of_arguments(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_init)\n\u001B[0;32m   1259\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_init_argcount \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 1260\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1261\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m model_init_argcount \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1262\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_init(trial)\n",
      "Input \u001B[1;32mIn [48]\u001B[0m, in \u001B[0;36mmodel_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmodel_init\u001B[39m():\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[43mXLMRobertaForTokenClassification\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxlmr_model_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxlmr_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m----> 4\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\transformers\\modeling_utils.py:1749\u001B[0m, in \u001B[0;36mPreTrainedModel.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1744\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`.to` is not supported for `8-bit` models. Please use the model as it is, since the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1747\u001B[0m     )\n\u001B[0;32m   1748\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    923\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    924\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m    925\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[1;32m--> 927\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:579\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 579\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    581\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    582\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    583\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    584\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    589\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    590\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:579\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 579\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    581\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    582\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    583\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    584\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    589\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    590\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:579\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 579\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    581\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    582\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    583\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    584\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    589\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    590\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:602\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    599\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    600\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    601\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 602\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    603\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    604\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\.conda\\envs\\qw\\lib\\site-packages\\torch\\nn\\modules\\module.py:925\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    922\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m    923\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    924\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m--> 925\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 734.00 MiB (GPU 0; 12.00 GiB total capacity; 10.35 GiB already allocated; 0 bytes free; 10.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "training_args.push_to_hub = False\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "# Hack needed to exclude the progress bars in the above cell\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "for num_samples in [500, 1000, 2000, 4000]:\n",
    "    metrics_df = metrics_df.append(\n",
    "        train_on_subset(panx_fr_encoded, num_samples), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"269.55125pt\" version=\"1.1\" viewBox=\"0 0 386.73125 269.55125\" width=\"386.73125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-10-24T12:35:59.543256</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 269.55125 \nL 386.73125 269.55125 \nL 386.73125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 44.73125 229.044375 \nL 379.53125 229.044375 \nL 379.53125 11.604375 \nL 44.73125 11.604375 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m99b8793981\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"80.240341\" xlink:href=\"#m99b8793981\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 500 -->\n      <g transform=\"translate(71.294716 244.853125)scale(0.12 -0.12)\">\n       <defs>\n        <path d=\"M 1094 -64 \nC 1971 -64 2445 512 2445 1363 \nC 2445 2298 1997 2707 1165 2707 \nC 1011 2707 890 2694 794 2675 \nL 877 3974 \nL 2342 3974 \nL 2342 4435 \nL 429 4435 \nL 294 2170 \nC 467 2208 710 2246 966 2246 \nC 1587 2246 1875 1990 1875 1363 \nC 1875 717 1587 397 954 397 \nC 627 397 365 474 154 582 \nL 154 147 \nC 352 26 672 -64 1094 -64 \nz\n\" id=\"GuardianSansCond-Regular-35\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 1722 -70 \nC 2656 -70 3155 646 3155 2061 \nL 3155 2406 \nC 3155 3891 2598 4499 1715 4499 \nC 819 4499 269 3834 269 2368 \nL 269 2042 \nC 269 499 845 -70 1722 -70 \nz\nM 1728 384 \nC 1069 384 845 979 845 2016 \nL 845 2490 \nC 845 3494 1088 4051 1709 4051 \nC 2336 4051 2592 3514 2592 2458 \nL 2592 1978 \nC 2592 934 2374 384 1728 384 \nz\n\" id=\"GuardianSansCond-Regular-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#GuardianSansCond-Regular-35\"/>\n       <use x=\"42.099991\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"95.599976\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"120.822159\" xlink:href=\"#m99b8793981\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1000 -->\n      <g transform=\"translate(109.464347 244.853125)scale(0.12 -0.12)\">\n       <defs>\n        <path d=\"M 832 0 \nL 1363 0 \nL 1363 4474 \nL 1171 4474 \nL 141 4083 \nL 141 3776 \nL 832 3846 \nL 832 0 \nz\n\" id=\"GuardianSansCond-Regular-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#GuardianSansCond-Regular-31\"/>\n       <use x=\"28.799988\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"82.299973\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"135.799957\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"161.403977\" xlink:href=\"#m99b8793981\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1500 -->\n      <g transform=\"translate(150.73054 244.853125)scale(0.12 -0.12)\">\n       <use xlink:href=\"#GuardianSansCond-Regular-31\"/>\n       <use x=\"28.799988\" xlink:href=\"#GuardianSansCond-Regular-35\"/>\n       <use x=\"70.899979\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"124.399963\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"201.985795\" xlink:href=\"#m99b8793981\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2000 -->\n      <g transform=\"translate(189.805795 244.853125)scale(0.12 -0.12)\">\n       <defs>\n        <path d=\"M 173 0 \nL 2470 0 \nL 2470 461 \nL 800 461 \nL 800 480 \nL 1574 1421 \nC 2067 2035 2419 2528 2419 3264 \nC 2419 4026 2029 4499 1222 4499 \nC 806 4499 499 4410 269 4282 \nL 269 3853 \nC 467 3949 730 4032 1056 4032 \nC 1619 4032 1850 3750 1850 3213 \nC 1850 2630 1542 2189 1152 1670 \nL 173 397 \nL 173 0 \nz\n\" id=\"GuardianSansCond-Regular-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#GuardianSansCond-Regular-32\"/>\n       <use x=\"42.499985\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"95.999969\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"149.499954\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"242.567614\" xlink:href=\"#m99b8793981\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2500 -->\n      <g transform=\"translate(231.071989 244.853125)scale(0.12 -0.12)\">\n       <use xlink:href=\"#GuardianSansCond-Regular-32\"/>\n       <use x=\"42.499985\" xlink:href=\"#GuardianSansCond-Regular-35\"/>\n       <use x=\"84.599976\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"138.09996\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"283.149432\" xlink:href=\"#m99b8793981\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3000 -->\n      <g transform=\"translate(270.987244 244.853125)scale(0.12 -0.12)\">\n       <defs>\n        <path d=\"M 1094 -64 \nC 1920 -64 2432 416 2432 1248 \nC 2432 1939 2112 2253 1606 2362 \nL 1606 2381 \nC 2042 2515 2310 2803 2310 3405 \nC 2310 4096 1882 4499 1158 4499 \nC 787 4499 486 4429 275 4320 \nL 275 3891 \nC 461 3968 678 4038 998 4038 \nC 1478 4038 1754 3866 1754 3302 \nC 1754 2797 1478 2547 1018 2547 \nL 717 2547 \nL 717 2086 \nL 1056 2086 \nC 1600 2086 1869 1837 1869 1267 \nC 1869 646 1517 403 947 403 \nC 646 403 358 493 147 608 \nL 147 166 \nC 358 32 640 -64 1094 -64 \nz\n\" id=\"GuardianSansCond-Regular-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#GuardianSansCond-Regular-33\"/>\n       <use x=\"42.199997\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"95.699982\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"149.199966\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"323.73125\" xlink:href=\"#m99b8793981\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 3500 -->\n      <g transform=\"translate(312.253438 244.853125)scale(0.12 -0.12)\">\n       <use xlink:href=\"#GuardianSansCond-Regular-33\"/>\n       <use x=\"42.199997\" xlink:href=\"#GuardianSansCond-Regular-35\"/>\n       <use x=\"84.299988\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"137.799973\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"364.313068\" xlink:href=\"#m99b8793981\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4000 -->\n      <g transform=\"translate(351.838693 244.853125)scale(0.12 -0.12)\">\n       <defs>\n        <path d=\"M 1805 0 \nL 2330 0 \nL 2330 1107 \nL 2957 1107 \nL 2957 1562 \nL 2330 1562 \nL 2330 4435 \nL 1869 4435 \nL 70 1504 \nL 70 1107 \nL 1805 1107 \nL 1805 0 \nz\nM 608 1562 \nL 608 1581 \nL 1779 3475 \nL 1805 3475 \nL 1805 1562 \nL 608 1562 \nz\n\" id=\"GuardianSansCond-Regular-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#GuardianSansCond-Regular-34\"/>\n       <use x=\"47.399994\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"100.899979\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"154.399963\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- Number of Training Samples -->\n     <g transform=\"translate(152.613125 260.035625)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 416 0 \nL 909 0 \nL 909 2912 \nC 909 3424 877 3757 877 3757 \nL 896 3757 \nC 896 3757 1050 3322 1274 2822 \nL 2547 0 \nL 3155 0 \nL 3155 4435 \nL 2662 4435 \nL 2662 1568 \nC 2662 1114 2694 762 2694 762 \nL 2682 762 \nC 2682 762 2502 1254 2330 1626 \nL 1094 4435 \nL 416 4435 \nL 416 0 \nz\n\" id=\"GuardianSansCond-Regular-4e\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1158 -51 \nC 1523 -51 1824 109 2042 262 \nL 2067 262 \nL 2118 0 \nL 2566 0 \nL 2566 3283 \nL 2042 3283 \nL 2042 602 \nC 1888 512 1626 397 1350 397 \nC 947 397 858 557 858 838 \nL 858 3283 \nL 333 3283 \nL 333 826 \nC 333 301 576 -51 1158 -51 \nz\n\" id=\"GuardianSansCond-Regular-75\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 346 0 \nL 870 0 \nL 870 2688 \nC 1050 2790 1267 2886 1523 2886 \nC 1856 2886 1971 2758 1971 2464 \nL 1971 0 \nL 2490 0 \nL 2490 2688 \nC 2682 2797 2912 2886 3136 2886 \nC 3488 2886 3590 2746 3590 2464 \nL 3590 0 \nL 4115 0 \nL 4115 2528 \nC 4115 3104 3821 3334 3347 3334 \nC 2995 3334 2688 3187 2419 2995 \nL 2394 2995 \nC 2266 3226 2061 3334 1722 3334 \nC 1395 3334 1088 3181 870 3021 \nL 845 3021 \nL 845 3283 \nL 346 3283 \nL 346 0 \nz\n\" id=\"GuardianSansCond-Regular-6d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1382 -64 \nC 2317 -64 2784 531 2784 1619 \nL 2784 1843 \nC 2784 2995 2285 3334 1702 3334 \nC 1338 3334 1075 3219 896 3104 \nL 870 3104 \nL 870 4698 \nL 346 4698 \nL 346 102 \nC 557 19 1005 -64 1382 -64 \nz\nM 1408 378 \nC 1165 378 979 416 870 454 \nL 870 2733 \nC 992 2790 1216 2893 1491 2893 \nC 2003 2893 2246 2650 2246 1818 \nL 2246 1549 \nC 2246 627 1875 378 1408 378 \nz\n\" id=\"GuardianSansCond-Regular-62\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1555 -51 \nC 1984 -51 2317 102 2470 243 \nL 2470 627 \nC 2240 499 1965 397 1613 397 \nC 1037 397 742 698 723 1466 \nL 2554 1466 \nL 2554 1798 \nC 2554 2893 2176 3334 1402 3334 \nC 659 3334 186 2810 186 1722 \nL 186 1549 \nC 186 499 634 -51 1555 -51 \nz\nM 1382 2906 \nC 1830 2906 2010 2611 2010 1894 \nL 723 1894 \nC 736 2630 992 2906 1382 2906 \nz\n\" id=\"GuardianSansCond-Regular-65\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 346 0 \nL 870 0 \nL 870 2605 \nC 1062 2752 1306 2842 1587 2842 \nC 1638 2842 1728 2835 1786 2829 \nL 1786 3302 \nC 1747 3315 1677 3328 1606 3328 \nC 1306 3328 1030 3142 870 2938 \nL 845 2938 \nL 845 3283 \nL 346 3283 \nL 346 0 \nz\n\" id=\"GuardianSansCond-Regular-72\" transform=\"scale(0.015625)\"/>\n       <path id=\"GuardianSansCond-Regular-20\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1459 -51 \nC 2272 -51 2733 570 2733 1542 \nL 2733 1747 \nC 2733 2771 2291 3334 1459 3334 \nC 659 3334 186 2714 186 1741 \nL 186 1530 \nC 186 531 614 -51 1459 -51 \nz\nM 1466 378 \nC 992 378 723 762 723 1472 \nL 723 1818 \nC 723 2451 947 2906 1453 2906 \nC 1920 2906 2195 2560 2195 1805 \nL 2195 1466 \nC 2195 826 1958 378 1466 378 \nz\n\" id=\"GuardianSansCond-Regular-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 493 0 \nL 1018 0 \nL 1018 2848 \nL 1626 2848 \nL 1626 3283 \nL 1018 3283 \nL 1018 3712 \nC 1018 4115 1146 4307 1478 4307 \nC 1632 4307 1754 4282 1837 4262 \nL 1837 4640 \nC 1747 4685 1587 4742 1363 4742 \nC 826 4742 493 4429 493 3757 \nL 493 3283 \nL 96 3283 \nL 96 2848 \nL 493 2848 \nL 493 0 \nz\n\" id=\"GuardianSansCond-Regular-66\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1152 0 \nL 1690 0 \nL 1690 3974 \nL 2746 3974 \nL 2746 4435 \nL 90 4435 \nL 90 3974 \nL 1152 3974 \nL 1152 0 \nz\n\" id=\"GuardianSansCond-Regular-54\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1082 -51 \nC 1395 -51 1638 77 1779 230 \nL 1811 230 \nL 1862 0 \nL 2291 0 \nL 2291 2413 \nC 2291 3027 1958 3334 1293 3334 \nC 915 3334 634 3258 410 3155 \nL 410 2771 \nC 576 2829 806 2886 1094 2886 \nC 1600 2886 1766 2739 1766 2278 \nL 1766 1958 \nL 1088 1856 \nC 480 1766 160 1466 160 883 \nC 160 250 525 -51 1082 -51 \nz\nM 1222 358 \nC 877 358 704 544 704 915 \nC 704 1274 877 1440 1242 1485 \nL 1766 1549 \nL 1766 525 \nC 1658 435 1459 358 1222 358 \nz\n\" id=\"GuardianSansCond-Regular-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 358 0 \nL 883 0 \nL 883 3283 \nL 358 3283 \nL 358 0 \nz\nM 352 3910 \nL 883 3910 \nL 883 4474 \nL 352 4474 \nL 352 3910 \nz\n\" id=\"GuardianSansCond-Regular-69\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 346 0 \nL 870 0 \nL 870 2688 \nC 1037 2778 1306 2886 1587 2886 \nC 1965 2886 2093 2765 2093 2458 \nL 2093 0 \nL 2611 0 \nL 2611 2528 \nC 2611 3085 2342 3334 1811 3334 \nC 1440 3334 1107 3194 870 3021 \nL 845 3021 \nL 845 3283 \nL 346 3283 \nL 346 0 \nz\n\" id=\"GuardianSansCond-Regular-6e\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1325 -1235 \nC 2240 -1235 2675 -787 2675 -179 \nC 2675 416 2336 704 1696 704 \nL 1069 704 \nC 858 704 774 806 774 966 \nC 774 1069 826 1178 890 1242 \nC 1018 1197 1171 1178 1331 1178 \nC 1939 1178 2413 1530 2413 2208 \nL 2413 2304 \nC 2413 2560 2336 2739 2234 2874 \nL 2682 2874 \nL 2682 3283 \nL 1747 3283 \nC 1626 3315 1485 3334 1325 3334 \nC 704 3334 250 2944 250 2278 \nL 250 2182 \nC 250 1786 429 1510 634 1376 \nC 422 1210 294 1024 294 787 \nC 294 544 442 403 627 333 \nL 627 307 \nC 320 192 64 -38 64 -422 \nC 64 -915 506 -1235 1325 -1235 \nz\nM 1312 -819 \nC 832 -819 595 -640 595 -326 \nC 595 -51 762 141 966 218 \nL 1632 218 \nC 2022 218 2150 45 2150 -237 \nC 2150 -602 1926 -819 1312 -819 \nz\nM 1331 1581 \nC 998 1581 762 1773 762 2189 \nL 762 2323 \nC 762 2726 973 2931 1331 2931 \nC 1670 2931 1901 2746 1901 2310 \nL 1901 2176 \nC 1901 1779 1683 1581 1331 1581 \nz\n\" id=\"GuardianSansCond-Regular-67\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1184 -70 \nC 2138 -70 2509 499 2509 1248 \nC 2509 2029 2112 2259 1562 2502 \nL 1242 2643 \nC 858 2810 730 2970 730 3360 \nC 730 3808 986 4038 1459 4038 \nC 1843 4038 2144 3936 2336 3840 \nL 2336 4301 \nC 2157 4397 1914 4499 1466 4499 \nC 653 4499 198 4058 198 3322 \nC 198 2637 544 2349 1024 2138 \nL 1344 1997 \nC 1760 1811 1958 1677 1958 1197 \nC 1958 659 1702 397 1146 397 \nC 794 397 442 512 166 646 \nL 166 186 \nC 390 51 723 -70 1184 -70 \nz\n\" id=\"GuardianSansCond-Regular-53\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 346 -1222 \nL 870 -1222 \nL 870 128 \nC 1005 38 1242 -51 1542 -51 \nC 2374 -51 2784 525 2784 1600 \nL 2784 1818 \nC 2784 2912 2342 3334 1670 3334 \nC 1318 3334 1030 3187 870 3034 \nL 845 3034 \nL 845 3283 \nL 346 3283 \nL 346 -1222 \nz\nM 1466 378 \nC 1210 378 973 461 870 538 \nL 870 2688 \nC 992 2784 1229 2893 1523 2893 \nC 2035 2893 2246 2573 2246 1798 \nL 2246 1549 \nC 2246 742 2003 378 1466 378 \nz\n\" id=\"GuardianSansCond-Regular-70\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 358 0 \nL 877 0 \nL 877 4698 \nL 358 4698 \nL 358 0 \nz\n\" id=\"GuardianSansCond-Regular-6c\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 992 -51 \nC 1658 -51 2054 307 2054 947 \nC 2054 1485 1818 1709 1306 1888 \nL 1050 1978 \nC 768 2074 659 2195 659 2451 \nC 659 2771 864 2893 1222 2893 \nC 1517 2893 1760 2810 1914 2739 \nL 1914 3168 \nC 1773 3251 1568 3334 1197 3334 \nC 531 3334 160 2982 160 2406 \nC 160 1901 422 1658 826 1517 \nL 1082 1427 \nC 1408 1312 1536 1184 1536 896 \nC 1536 582 1370 390 934 390 \nC 582 390 358 480 154 563 \nL 154 141 \nC 358 19 640 -51 992 -51 \nz\n\" id=\"GuardianSansCond-Regular-73\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#GuardianSansCond-Regular-4e\"/>\n      <use x=\"55.799988\" xlink:href=\"#GuardianSansCond-Regular-75\"/>\n      <use x=\"101.299973\" xlink:href=\"#GuardianSansCond-Regular-6d\"/>\n      <use x=\"170.799957\" xlink:href=\"#GuardianSansCond-Regular-62\"/>\n      <use x=\"217.399948\" xlink:href=\"#GuardianSansCond-Regular-65\"/>\n      <use x=\"260.099945\" xlink:href=\"#GuardianSansCond-Regular-72\"/>\n      <use x=\"288.899933\" xlink:href=\"#GuardianSansCond-Regular-20\"/>\n      <use x=\"304.699921\" xlink:href=\"#GuardianSansCond-Regular-6f\"/>\n      <use x=\"350.299911\" xlink:href=\"#GuardianSansCond-Regular-66\"/>\n      <use x=\"376.999908\" xlink:href=\"#GuardianSansCond-Regular-20\"/>\n      <use x=\"392.799896\" xlink:href=\"#GuardianSansCond-Regular-54\"/>\n      <use x=\"437.299881\" xlink:href=\"#GuardianSansCond-Regular-72\"/>\n      <use x=\"466.099869\" xlink:href=\"#GuardianSansCond-Regular-61\"/>\n      <use x=\"506.999863\" xlink:href=\"#GuardianSansCond-Regular-69\"/>\n      <use x=\"526.29985\" xlink:href=\"#GuardianSansCond-Regular-6e\"/>\n      <use x=\"572.399841\" xlink:href=\"#GuardianSansCond-Regular-69\"/>\n      <use x=\"591.699829\" xlink:href=\"#GuardianSansCond-Regular-6e\"/>\n      <use x=\"637.79982\" xlink:href=\"#GuardianSansCond-Regular-67\"/>\n      <use x=\"680.499817\" xlink:href=\"#GuardianSansCond-Regular-20\"/>\n      <use x=\"696.299805\" xlink:href=\"#GuardianSansCond-Regular-53\"/>\n      <use x=\"738.499802\" xlink:href=\"#GuardianSansCond-Regular-61\"/>\n      <use x=\"779.399796\" xlink:href=\"#GuardianSansCond-Regular-6d\"/>\n      <use x=\"848.89978\" xlink:href=\"#GuardianSansCond-Regular-70\"/>\n      <use x=\"895.499771\" xlink:href=\"#GuardianSansCond-Regular-6c\"/>\n      <use x=\"914.799759\" xlink:href=\"#GuardianSansCond-Regular-65\"/>\n      <use x=\"957.499756\" xlink:href=\"#GuardianSansCond-Regular-73\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md8ae89ab47\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.73125\" xlink:href=\"#md8ae89ab47\" y=\"229.044375\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.0 -->\n      <g transform=\"translate(22.3 233.44875)scale(0.12 -0.12)\">\n       <defs>\n        <path d=\"M 397 0 \nL 986 0 \nL 986 621 \nL 397 621 \nL 397 0 \nz\n\" id=\"GuardianSansCond-Regular-2e\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"53.499985\" xlink:href=\"#GuardianSansCond-Regular-2e\"/>\n       <use x=\"75.099976\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.73125\" xlink:href=\"#md8ae89ab47\" y=\"185.556375\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.2 -->\n      <g transform=\"translate(23.62 189.96075)scale(0.12 -0.12)\">\n       <use xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"53.499985\" xlink:href=\"#GuardianSansCond-Regular-2e\"/>\n       <use x=\"75.099976\" xlink:href=\"#GuardianSansCond-Regular-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.73125\" xlink:href=\"#md8ae89ab47\" y=\"142.068375\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <g transform=\"translate(23.03125 146.47275)scale(0.12 -0.12)\">\n       <use xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"53.499985\" xlink:href=\"#GuardianSansCond-Regular-2e\"/>\n       <use x=\"75.099976\" xlink:href=\"#GuardianSansCond-Regular-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.73125\" xlink:href=\"#md8ae89ab47\" y=\"98.580375\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.6 -->\n      <g transform=\"translate(22.85125 102.98475)scale(0.12 -0.12)\">\n       <defs>\n        <path d=\"M 1632 384 \nC 1082 384 845 915 845 1837 \nL 845 2054 \nC 992 2150 1254 2278 1594 2278 \nC 2086 2278 2323 1984 2323 1357 \nC 2323 742 2086 384 1632 384 \nz\nM 1632 -70 \nC 2438 -70 2886 544 2886 1408 \nC 2886 2234 2490 2746 1754 2746 \nC 1363 2746 1056 2611 845 2445 \nC 877 3853 1440 4038 2029 4038 \nC 2291 4038 2554 3974 2688 3930 \nL 2688 4352 \nC 2547 4442 2272 4499 1958 4499 \nC 1043 4499 275 3981 275 2208 \nL 275 1843 \nC 275 691 717 -70 1632 -70 \nz\n\" id=\"GuardianSansCond-Regular-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"53.499985\" xlink:href=\"#GuardianSansCond-Regular-2e\"/>\n       <use x=\"75.099976\" xlink:href=\"#GuardianSansCond-Regular-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.73125\" xlink:href=\"#md8ae89ab47\" y=\"55.092375\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.8 -->\n      <g transform=\"translate(22.79125 59.49675)scale(0.12 -0.12)\">\n       <defs>\n        <path d=\"M 1581 -64 \nC 2445 -64 2931 467 2931 1139 \nC 2931 1760 2592 2074 2106 2330 \nC 2490 2541 2822 2899 2822 3424 \nC 2822 4077 2394 4499 1606 4499 \nC 819 4499 384 4013 384 3398 \nC 384 2848 678 2509 1069 2285 \nC 602 2054 230 1683 230 1082 \nC 230 384 710 -64 1581 -64 \nz\nM 1587 390 \nC 1082 390 768 678 768 1126 \nC 768 1581 1037 1894 1414 2080 \nC 2029 1792 2387 1574 2387 1082 \nC 2387 614 2054 390 1587 390 \nz\nM 1754 2522 \nC 1210 2778 928 3021 928 3430 \nC 928 3821 1171 4051 1606 4051 \nC 2067 4051 2285 3782 2285 3398 \nC 2285 3008 2099 2765 1754 2522 \nz\n\" id=\"GuardianSansCond-Regular-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#GuardianSansCond-Regular-30\"/>\n       <use x=\"53.499985\" xlink:href=\"#GuardianSansCond-Regular-2e\"/>\n       <use x=\"75.099976\" xlink:href=\"#GuardianSansCond-Regular-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.73125\" xlink:href=\"#md8ae89ab47\" y=\"11.604375\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.0 -->\n      <g transform=\"translate(25.264375 16.00875)scale(0.12 -0.12)\">\n       <use xlink:href=\"#GuardianSansCond-Regular-31\"/>\n       <use x=\"28.799988\" xlink:href=\"#GuardianSansCond-Regular-2e\"/>\n       <use x=\"50.399979\" xlink:href=\"#GuardianSansCond-Regular-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- F1 Score -->\n     <g transform=\"translate(16.00875 137.375625)rotate(-90)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 416 0 \nL 954 0 \nL 954 1984 \nL 2227 1984 \nL 2227 2445 \nL 954 2445 \nL 954 3974 \nL 2573 3974 \nL 2573 4435 \nL 416 4435 \nL 416 0 \nz\n\" id=\"GuardianSansCond-Regular-46\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1498 -51 \nC 1869 -51 2125 51 2298 173 \nL 2298 595 \nC 2163 518 1907 390 1555 390 \nC 1005 390 723 704 723 1542 \nL 723 1798 \nC 723 2464 941 2893 1510 2893 \nC 1856 2893 2054 2803 2259 2714 \nL 2259 3149 \nC 2093 3258 1875 3334 1542 3334 \nC 768 3334 186 2886 186 1741 \nL 186 1536 \nC 186 416 685 -51 1498 -51 \nz\n\" id=\"GuardianSansCond-Regular-63\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#GuardianSansCond-Regular-46\"/>\n      <use x=\"42.499985\" xlink:href=\"#GuardianSansCond-Regular-31\"/>\n      <use x=\"71.299973\" xlink:href=\"#GuardianSansCond-Regular-20\"/>\n      <use x=\"87.09996\" xlink:href=\"#GuardianSansCond-Regular-53\"/>\n      <use x=\"129.299957\" xlink:href=\"#GuardianSansCond-Regular-63\"/>\n      <use x=\"167.099945\" xlink:href=\"#GuardianSansCond-Regular-6f\"/>\n      <use x=\"212.699936\" xlink:href=\"#GuardianSansCond-Regular-72\"/>\n      <use x=\"241.499924\" xlink:href=\"#GuardianSansCond-Regular-65\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pcb9ab5d13c)\" d=\"M 44.73125 73.775275 \nL 379.53125 73.775275 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pcb9ab5d13c)\" d=\"M 59.949432 199.183608 \nL 80.240341 81.05556 \nL 120.822159 62.288426 \nL 201.985795 54.803464 \nL 364.313068 46.182096 \n\" style=\"fill:none;stroke:#0071bc;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 44.73125 229.044375 \nL 44.73125 11.604375 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 379.53125 229.044375 \nL 379.53125 11.604375 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 44.73125 229.044375 \nL 379.53125 229.044375 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 44.73125 11.604375 \nL 379.53125 11.604375 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 256.48625 223.044375 \nL 371.13125 223.044375 \nQ 373.53125 223.044375 373.53125 220.644375 \nL 373.53125 187.644375 \nQ 373.53125 185.244375 371.13125 185.244375 \nL 256.48625 185.244375 \nQ 254.08625 185.244375 254.08625 187.644375 \nL 254.08625 220.644375 \nQ 254.08625 223.044375 256.48625 223.044375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 258.88625 194.653125 \nL 282.88625 194.653125 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_17\">\n     <!-- Zero-shot from de -->\n     <g transform=\"translate(292.48625 198.853125)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 160 0 \nL 2630 0 \nL 2630 461 \nL 781 461 \nL 781 480 \nL 2688 4032 \nL 2688 4435 \nL 301 4435 \nL 301 3974 \nL 2054 3974 \nL 2054 3955 \nL 160 397 \nL 160 0 \nz\n\" id=\"GuardianSansCond-Regular-5a\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 333 1536 \nL 1408 1536 \nL 1408 1990 \nL 333 1990 \nL 333 1536 \nz\n\" id=\"GuardianSansCond-Regular-2d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 346 0 \nL 870 0 \nL 870 2688 \nC 1037 2778 1306 2886 1587 2886 \nC 1965 2886 2093 2765 2093 2458 \nL 2093 0 \nL 2611 0 \nL 2611 2528 \nC 2611 3085 2336 3334 1805 3334 \nC 1440 3334 1126 3200 896 3034 \nL 870 3034 \nL 870 4698 \nL 346 4698 \nL 346 0 \nz\n\" id=\"GuardianSansCond-Regular-68\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1222 -38 \nC 1466 -38 1619 26 1722 90 \nL 1722 442 \nC 1632 416 1517 390 1382 390 \nC 1107 390 1005 480 1005 781 \nL 1005 2848 \nL 1683 2848 \nL 1683 3283 \nL 1005 3283 \nL 1005 4051 \nL 486 4051 \nL 486 3283 \nL 96 3283 \nL 96 2848 \nL 486 2848 \nL 486 710 \nC 486 160 774 -38 1222 -38 \nz\n\" id=\"GuardianSansCond-Regular-74\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1357 -51 \nC 1690 -51 1965 77 2125 243 \nL 2150 243 \nL 2195 0 \nL 2637 0 \nL 2637 4698 \nL 2118 4698 \nL 2118 3174 \nC 1978 3264 1734 3334 1466 3334 \nC 634 3334 198 2739 198 1670 \nL 198 1523 \nC 198 339 723 -51 1357 -51 \nz\nM 1504 378 \nC 992 378 742 749 742 1542 \nL 742 1728 \nC 742 2541 979 2893 1536 2893 \nC 1779 2893 2003 2835 2118 2758 \nL 2118 595 \nC 1984 493 1773 378 1504 378 \nz\n\" id=\"GuardianSansCond-Regular-64\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#GuardianSansCond-Regular-5a\"/>\n      <use x=\"44.399994\" xlink:href=\"#GuardianSansCond-Regular-65\"/>\n      <use x=\"87.099991\" xlink:href=\"#GuardianSansCond-Regular-72\"/>\n      <use x=\"115.899979\" xlink:href=\"#GuardianSansCond-Regular-6f\"/>\n      <use x=\"161.499969\" xlink:href=\"#GuardianSansCond-Regular-2d\"/>\n      <use x=\"188.699966\" xlink:href=\"#GuardianSansCond-Regular-73\"/>\n      <use x=\"223.199951\" xlink:href=\"#GuardianSansCond-Regular-68\"/>\n      <use x=\"269.299942\" xlink:href=\"#GuardianSansCond-Regular-6f\"/>\n      <use x=\"314.899933\" xlink:href=\"#GuardianSansCond-Regular-74\"/>\n      <use x=\"343.899918\" xlink:href=\"#GuardianSansCond-Regular-20\"/>\n      <use x=\"359.699905\" xlink:href=\"#GuardianSansCond-Regular-66\"/>\n      <use x=\"386.399902\" xlink:href=\"#GuardianSansCond-Regular-72\"/>\n      <use x=\"415.19989\" xlink:href=\"#GuardianSansCond-Regular-6f\"/>\n      <use x=\"460.799881\" xlink:href=\"#GuardianSansCond-Regular-6d\"/>\n      <use x=\"530.299866\" xlink:href=\"#GuardianSansCond-Regular-20\"/>\n      <use x=\"546.099854\" xlink:href=\"#GuardianSansCond-Regular-64\"/>\n      <use x=\"592.699844\" xlink:href=\"#GuardianSansCond-Regular-65\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 258.88625 211.753125 \nL 282.88625 211.753125 \n\" style=\"fill:none;stroke:#0071bc;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_18\">\n     <!-- Fine-tuned on fr -->\n     <g transform=\"translate(292.48625 215.953125)scale(0.12 -0.12)\">\n      <use xlink:href=\"#GuardianSansCond-Regular-46\"/>\n      <use x=\"42.499985\" xlink:href=\"#GuardianSansCond-Regular-69\"/>\n      <use x=\"61.799973\" xlink:href=\"#GuardianSansCond-Regular-6e\"/>\n      <use x=\"107.899963\" xlink:href=\"#GuardianSansCond-Regular-65\"/>\n      <use x=\"150.59996\" xlink:href=\"#GuardianSansCond-Regular-2d\"/>\n      <use x=\"177.799957\" xlink:href=\"#GuardianSansCond-Regular-74\"/>\n      <use x=\"206.799942\" xlink:href=\"#GuardianSansCond-Regular-75\"/>\n      <use x=\"252.299927\" xlink:href=\"#GuardianSansCond-Regular-6e\"/>\n      <use x=\"298.399918\" xlink:href=\"#GuardianSansCond-Regular-65\"/>\n      <use x=\"341.099915\" xlink:href=\"#GuardianSansCond-Regular-64\"/>\n      <use x=\"387.699905\" xlink:href=\"#GuardianSansCond-Regular-20\"/>\n      <use x=\"403.499893\" xlink:href=\"#GuardianSansCond-Regular-6f\"/>\n      <use x=\"449.099884\" xlink:href=\"#GuardianSansCond-Regular-6e\"/>\n      <use x=\"495.199875\" xlink:href=\"#GuardianSansCond-Regular-20\"/>\n      <use x=\"510.999863\" xlink:href=\"#GuardianSansCond-Regular-66\"/>\n      <use x=\"537.69986\" xlink:href=\"#GuardianSansCond-Regular-72\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pcb9ab5d13c\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"44.73125\" y=\"11.604375\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.axhline(f1_scores[\"de\"][\"fr\"], ls=\"--\", color=\"r\")\n",
    "metrics_df.set_index(\"num_samples\").plot(ax=ax)\n",
    "plt.legend([\"Zero-shot from de\", \"Fine-tuned on fr\"], loc=\"lower right\")\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning on Multiple Languages at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "def concatenate_splits(corpora):\n",
    "    multi_corpus = DatasetDict()\n",
    "    for split in corpora[0].keys():\n",
    "        multi_corpus[split] = concatenate_datasets(\n",
    "            [corpus[split] for corpus in corpora]).shuffle(seed=42)\n",
    "    return multi_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de_fr_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "training_args.logging_steps = len(panx_de_fr_encoded[\"train\"]) // batch_size\n",
    "training_args.push_to_hub = True\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=panx_de_fr_encoded[\"train\"],\n",
    "    eval_dataset=panx_de_fr_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [de] dataset: 0.866\n",
      "F1-score of [de-fr] model on [fr] dataset: 0.868\n",
      "F1-score of [de-fr] model on [it] dataset: 0.815\n",
      "F1-score of [de-fr] model on [en] dataset: 0.677\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [de] dataset: 0.866\n",
      "F1-score of [de-fr] model on [fr] dataset: 0.868\n",
      "F1-score of [de-fr] model on [it] dataset: 0.815\n",
      "F1-score of [de-fr] model on [en] dataset: 0.677\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([DatasetDict({\n",
       "      train: Dataset({\n",
       "          features: ['input_ids', 'attention_mask', 'labels'],\n",
       "          num_rows: 12580\n",
       "      })\n",
       "      validation: Dataset({\n",
       "          features: ['input_ids', 'attention_mask', 'labels'],\n",
       "          num_rows: 6290\n",
       "      })\n",
       "      test: Dataset({\n",
       "          features: ['input_ids', 'attention_mask', 'labels'],\n",
       "          num_rows: 6290\n",
       "      })\n",
       "  })],\n",
       " ['de', 'fr', 'it', 'en'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "corpora = [panx_de_encoded]\n",
    "corpora, langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c58718a2a04910b212db2d76db77a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-88460cc0709a509a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\qilin\\.cache\\huggingface\\datasets\\xtreme\\PAN-X.fr\\1.0.0\\29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4\\cache-b04adacda5246119.arrow\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_on_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [105]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Fine-tune on monolingual corpus\u001B[39;00m\n\u001B[0;32m      5\u001B[0m ds_encoded \u001B[38;5;241m=\u001B[39m encode_panx_dataset(panx_ch[lang])\n\u001B[1;32m----> 6\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_on_subset\u001B[49m(ds_encoded, ds_encoded[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mnum_rows)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Collect F1-scores in common dict\u001B[39;00m\n\u001B[0;32m      8\u001B[0m f1_scores[lang][lang] \u001B[38;5;241m=\u001B[39m metrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1_score\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_on_subset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exclude German from iteration\n",
    "for lang in langs[1:]:\n",
    "    training_args.output_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n",
    "    # Fine-tune on monolingual corpus\n",
    "    ds_encoded = encode_panx_dataset(panx_ch[lang])\n",
    "    metrics = train_on_subset(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
    "    # Collect F1-scores in common dict\n",
    "    f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
    "    # Add monolingual corpus to list of corpora to concatenate\n",
    "    corpora.append(ds_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_encoded = concatenate_splits(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpora_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [102]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# hide_output\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m training_args\u001B[38;5;241m.\u001B[39mlogging_steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mcorpora_encoded\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m batch_size\n\u001B[0;32m      3\u001B[0m training_args\u001B[38;5;241m.\u001B[39moutput_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxlm-roberta-base-finetuned-panx-all\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      5\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(model_init\u001B[38;5;241m=\u001B[39mmodel_init, args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m      6\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mdata_collator, compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[0;32m      7\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mxlmr_tokenizer, train_dataset\u001B[38;5;241m=\u001B[39mcorpora_encoded[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m      8\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mcorpora_encoded[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'corpora_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],\n",
    "    eval_dataset=corpora_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='419' max='263' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [263/263 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "for idx, lang in enumerate(langs):\n",
    "    f1_scores[\"all\"][lang] = get_f1_score(trainer, corpora[idx][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluated on</th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine-tune on</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.7141</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.8192</td>\n",
       "      <td>0.7068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.7870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluated on      de      fr      it      en\n",
       "Fine-tune on                                \n",
       "de            0.8677  0.7141  0.6923  0.5890\n",
       "each          0.8677  0.8505  0.8192  0.7068\n",
       "all           0.8682  0.8647  0.8575  0.7870"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_data = {\"de\": f1_scores[\"de\"],\n",
    "               \"each\": {lang: f1_scores[lang][lang] for lang in langs},\n",
    "               \"all\": f1_scores[\"all\"]}\n",
    "f1_scores_df = pd.DataFrame(scores_data).T.round(4)\n",
    "f1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\",\n",
    "                         inplace=True)\n",
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with Model Widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"A Hub widget\" caption=\"Example of a widget on the Hugging Face Hub\" src=\"images/chapter04_ner-widget.png\" id=\"ner-widget\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
